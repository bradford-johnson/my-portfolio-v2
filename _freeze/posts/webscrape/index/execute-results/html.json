{
  "hash": "f99a008e401f1b3d7eaf14d2641c2cea",
  "result": {
    "markdown": "---\ntitle: \"Web Scraping with `rvest`\"\nauthor: \"Bradford Johnson\"\ndate: \"2022-09-18\"\nimage: \"josh-berendes-2zcemW2Oy8Y-unsplash.jpg\"\ncategories: [web scraping, rvest]\n---\n\n\n## **How to Web Scrape with `rvest`**\n\nUsing the `rvest` package you can get the data you need from webpages and quickly use it for analysis.\n\nBelow I will show a simple script using the `rvest`, `lubridate` and `tidyverse` packages that can scrape us some data from Wikipedia about the Seinfeld original television soundtrack.\n\nFirst of course install and load the packages, if you already have any of these packages then you just need to load them.\n\n## Install and Load Packages\n\n``` r\n# install packages\n    install.packages(\"tidyverse\")\n    install.packages(\"rvest\")\n    install.packages(\"lubridate\")\n\n# load packages\n    library(tidyverse)\n    library(rvest)\n    library(lubridate)\n```\n\n\n\n\n\nIf you want to see the documentation for any of these packages then click their hex image.\n\n[![rvest](https://github.com/rstudio/hex-stickers/blob/master/thumbs/rvest.png?raw=true)](https://rvest.tidyverse.org/) [![tidyverse](https://github.com/rstudio/hex-stickers/blob/master/thumbs/tidyverse.png?raw=true)](https://tidyverse.tidyverse.org/) [![lub](https://github.com/rstudio/hex-stickers/blob/master/thumbs/lubridate.png?raw=true)](https://lubridate.tidyverse.org/)\n\n## Setting the Parameters\n\nNext you will set up the parameters so `rvest` knows where to get the data from. The `html_nodes` can be found using the browser extension `SelectorGadget` found [here](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb). Using this extension you can highlight what you want to web scrape and copy/paste the html nodes from `SelectorGadget`.\n\n``` r\n# link to get data from\n    link <- \"https://en.wikipedia.org/wiki/Seinfeld\"\n\n# read webpage at the above link\n    page <- read_html(link)\n\n# scrape title\n    title <- page %>%\n        html_nodes(\".tracklist td:nth-child(2)\") %>%\n        html_text()\n\n# scrape episodes\n    episodes <- page %>%\n        html_nodes(\".tracklist td:nth-child(3)\") %>%\n        html_text()\n\n# scrape length\n    length <- page %>%\n        html_nodes(\".tracklist-length\") %>%\n        html_text()\n```\n\n\n\n\n\n## Creating the Data Frame\n\nAfter getting all the data you will want to put it into a data frame to work with it, so you will then use the `data.frame()` function and add in the data you pulled from online. Below you will see how I am creating the data frame and adding in the current date as a column so I know when I collected this data.\n\n``` r\n# create df\n    df <- data.frame(title, episodes, length)\n\n# remove quotes from data\n    df$title <- gsub(\"\\\"\", \"\", df$title)\n    df$episodes <- gsub(\"\\\"\", \"\", df$episodes)\n```\n\n\n\n\n\nNow lets see the first 6 rows of our new data frame that we crafted using `rvest`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# view top 6 records\n    head(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 title              episodes length\n1       Seinfeld Theme                     Â    0:52\n2       Seinfeld Theme The Highlights of 100   0:40\n3       Seinfeld Theme         The Chronicle   0:33\n4 The Jerry Show Theme     The Pilot, Part 2   0:50\n5    Kramer's Pimpwalk        The Wig Master   0:53\n6    Jerry the Mailman      The Andrea Doria   0:35\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}